{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01fae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local/yada/dev/slop-forensics-a\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ce8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r /local/yada/dev/slop-forensics-a/requirements.txt  \n",
    "\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('cmudict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d4719",
   "metadata": {},
   "source": [
    "## Sample Demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cfcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Example usage of the slop-forensics shortcuts module.\n",
    "This demonstrates how to use the unified analyze_sentences function.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "# project_root = os.path.dirname(os.path.abspath(__file__))\n",
    "# sys.path.insert(0, project_root)\n",
    "\n",
    "from slop_forensics.shortcuts import analyze_sentences, analyze_multiple_models\n",
    "\n",
    "def main():\n",
    "    # Example 1: Analyze a single set of sentences\n",
    "    print(\"=== Example 1: Single Model Analysis ===\")\n",
    "    \n",
    "    # Sample sentences that might contain \"slop\" (repetitive AI-generated text patterns)\n",
    "    sample_sentences = [\n",
    "        \"The sun was setting over the horizon, casting a warm glow across the landscape.\",\n",
    "        \"In conclusion, it's important to note that this matter requires careful consideration.\",\n",
    "        \"The atmosphere was filled with palpable tension as the characters navigated their journey.\",\n",
    "        \"It's worth mentioning that the situation demanded immediate attention and careful analysis.\",\n",
    "        \"The protagonist found themselves in a precarious situation that would test their resolve.\",\n",
    "        \"Furthermore, the implications of this decision would reverberate throughout the narrative.\",\n",
    "        \"The complex web of relationships added layers of depth to the unfolding drama.\",\n",
    "        \"As the story progressed, it became increasingly clear that the stakes were higher than anticipated.\",\n",
    "        \"The intricate plot threads began to weave together in unexpected ways.\",\n",
    "        \"Ultimately, the resolution provided a satisfying conclusion to the elaborate tale.\"\n",
    "    ]\n",
    "\n",
    "    sample_sentences = df[\"detailed\"].tolist()\n",
    "    \n",
    "    # Analyze the sentences\n",
    "    results = analyze_sentences(\n",
    "        sentences=sample_sentences,\n",
    "        output_dir=\"./analysis_results/example_1\",\n",
    "        model_name=\"sample_text\",\n",
    "        generate_phylogeny=False  # Skip phylogeny for single model\n",
    "    )\n",
    "    \n",
    "    print(f\"Analysis complete! Results saved to: ./analysis_results/example_1\")\n",
    "    print(f\"Summary statistics:\")\n",
    "    print(f\"  - Average length: {results['statistics'].get('avg_length', 0)}\")\n",
    "    print(f\"  - Slop score: {results['statistics'].get('slop_score', 0)}\")\n",
    "    print(f\"  - Repetitive words found: {results['statistics'].get('num_repetitive_words', 0)}\")\n",
    "    print(f\"  - Output files: {len(results['output_paths'])} files generated\")\n",
    "    print()\n",
    "    \n",
    "    # Example 2: Analyze multiple models/sources\n",
    "    print(\"=== Example 2: Multi-Model Analysis ===\")\n",
    "    \n",
    "    # Sample data from different \"models\" or sources\n",
    "    model_data = {\n",
    "        \"chatgpt_style\": [\n",
    "            \"I'd be happy to help you with that! Here's what you need to know about this topic.\",\n",
    "            \"It's important to note that there are several key considerations to keep in mind.\",\n",
    "            \"In summary, the best approach would be to carefully evaluate your options.\",\n",
    "            \"I hope this information helps! Let me know if you have any other questions.\",\n",
    "        ],\n",
    "        \"academic_style\": [\n",
    "            \"This research demonstrates significant implications for future studies in the field.\",\n",
    "            \"The methodology employed in this investigation follows established protocols.\",\n",
    "            \"Furthermore, the results indicate a strong correlation between the variables.\",\n",
    "            \"In conclusion, these findings contribute to our understanding of the phenomenon.\",\n",
    "        ],\n",
    "        \"creative_writing\": [\n",
    "            \"The moonlight danced across the rippling water, creating patterns of silver and shadow.\",\n",
    "            \"Her heart pounded with anticipation as she approached the mysterious door.\",\n",
    "            \"The ancient forest whispered secrets that only the wind could understand.\",\n",
    "            \"Time seemed to stand still in that magical moment of discovery.\",\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Analyze multiple models\n",
    "    multi_results = analyze_multiple_models(\n",
    "        model_sentences=model_data,\n",
    "        output_dir=\"./analysis_results/example_2\",\n",
    "        generate_phylogeny=True  # Generate phylogeny for multiple models\n",
    "    )\n",
    "    \n",
    "    print(f\"Multi-model analysis complete!\")\n",
    "    print(f\"Models analyzed: {multi_results['models_analyzed']}\")\n",
    "    print(f\"Total sentences: {multi_results['total_sentences']}\")\n",
    "    print(f\"Results saved to: ./analysis_results/example_2\")\n",
    "    print()\n",
    "    \n",
    "    print(\"=== Analysis Complete ===\")\n",
    "    print(\"Check the output directories for detailed results:\")\n",
    "    print(\"  - analysis_summary.json: Human-readable summary\")\n",
    "    print(\"  - slop_lists/: Generated slop word lists\")\n",
    "    print(\"  - phylogeny/: Phylogenetic tree visualizations (if generated)\")\n",
    "    print(\"  - analysis/: Detailed analysis metrics\")\n",
    "\n",
    "\n",
    "def quick_analyze(sentences, output_dir=\"./quick_analysis\"):\n",
    "    \"\"\"Quick analysis function for simple use cases.\"\"\"\n",
    "    results = analyze_sentences(\n",
    "        sentences=sentences,\n",
    "        output_dir=output_dir,\n",
    "        model_name=\"quick_analysis\",\n",
    "        generate_phylogeny=False\n",
    "    )\n",
    "    \n",
    "    # Print quick summary\n",
    "    print(\"Quick Analysis Results:\")\n",
    "    print(f\"  Sentences analyzed: {len(sentences)}\")\n",
    "    print(f\"  Average length: {results['statistics'].get('avg_length', 0):.1f} characters\")\n",
    "    print(f\"  Slop score: {results['statistics'].get('slop_score', 0):.3f}\")\n",
    "    print(f\"  Repetitive words: {results['statistics'].get('num_repetitive_words', 0)}\")\n",
    "    \n",
    "    # Show top repetitive words if any\n",
    "    analysis_file = results[\"output_paths\"].get(\"analysis\")\n",
    "    if analysis_file and os.path.exists(analysis_file):\n",
    "        import json\n",
    "        with open(analysis_file, 'r') as f:\n",
    "            analysis_data = json.load(f)\n",
    "        \n",
    "        top_words = analysis_data.get(\"top_repetitive_words\", [])[:5]\n",
    "        if top_words:\n",
    "            print(\"  Top repetitive words:\")\n",
    "            for word_data in top_words:\n",
    "                word = word_data.get(\"word\", \"\")\n",
    "                score = word_data.get(\"score\", 0)\n",
    "                print(f\"    - '{word}' (score: {score:.2f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4d75a3",
   "metadata": {},
   "source": [
    "## Doing on actual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42567eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 02:34:44,901 - INFO - logger - Loading from s3://quail-tmp/dive-vis-rubric-gemini-v7/image_list.parquet\n",
      "2025-07-22 02:34:44,909 - INFO - credentials - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s3key</th>\n",
       "      <th>image_id</th>\n",
       "      <th>index</th>\n",
       "      <th>detailed</th>\n",
       "      <th>short1</th>\n",
       "      <th>short1_1</th>\n",
       "      <th>short2</th>\n",
       "      <th>fallback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://bucket-public-access-uw2/labelling/dive-v...</td>\n",
       "      <td>danbooru-4178000</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a full-body digital illustration of a ...</td>\n",
       "      <td>This is a full-body character illustration in ...</td>\n",
       "      <td>A full-body character illustration, featuring ...</td>\n",
       "      <td>A cheerful anime girl with blue twin-drill hai...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://bucket-public-access-uw2/labelling/dive-v...</td>\n",
       "      <td>danbooru-6173968</td>\n",
       "      <td>1</td>\n",
       "      <td>In the upper right corner of the image, there ...</td>\n",
       "      <td>This is a digital illustration in a Japanese a...</td>\n",
       "      <td>A digital illustration presenting a portrait o...</td>\n",
       "      <td>In a suggestive pose, Seraphina from Disgaea 5...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3://bucket-public-access-uw2/labelling/dive-v...</td>\n",
       "      <td>danbooru-1410765</td>\n",
       "      <td>2</td>\n",
       "      <td>The image is a full-body, low-angle shot of a ...</td>\n",
       "      <td>This is a high-quality illustration in a Japan...</td>\n",
       "      <td>A high-quality illustration featuring the char...</td>\n",
       "      <td>A blushing, green-haired Sanae Kochiya in a st...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s3://bucket-public-access-uw2/labelling/dive-v...</td>\n",
       "      <td>danbooru-3560258</td>\n",
       "      <td>3</td>\n",
       "      <td>This is a high-detail Japanese anime-style ill...</td>\n",
       "      <td>This image is a Japanese anime-style illustrat...</td>\n",
       "      <td>An illustration of Hikari from Arcaea, present...</td>\n",
       "      <td>An ethereal illustration of Hikari from Arcaea...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s3://bucket-public-access-uw2/labelling/dive-v...</td>\n",
       "      <td>danbooru-2615484</td>\n",
       "      <td>4</td>\n",
       "      <td>This is a high-quality, Japanese anime-style d...</td>\n",
       "      <td>This is a dramatic and emotional Japanese anim...</td>\n",
       "      <td>A dramatic and emotional illustration of the c...</td>\n",
       "      <td>A distressed anime rabbit-girl with purple hai...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               s3key          image_id  index  \\\n",
       "0  s3://bucket-public-access-uw2/labelling/dive-v...  danbooru-4178000      0   \n",
       "1  s3://bucket-public-access-uw2/labelling/dive-v...  danbooru-6173968      1   \n",
       "2  s3://bucket-public-access-uw2/labelling/dive-v...  danbooru-1410765      2   \n",
       "3  s3://bucket-public-access-uw2/labelling/dive-v...  danbooru-3560258      3   \n",
       "4  s3://bucket-public-access-uw2/labelling/dive-v...  danbooru-2615484      4   \n",
       "\n",
       "                                            detailed  \\\n",
       "0  This is a full-body digital illustration of a ...   \n",
       "1  In the upper right corner of the image, there ...   \n",
       "2  The image is a full-body, low-angle shot of a ...   \n",
       "3  This is a high-detail Japanese anime-style ill...   \n",
       "4  This is a high-quality, Japanese anime-style d...   \n",
       "\n",
       "                                              short1  \\\n",
       "0  This is a full-body character illustration in ...   \n",
       "1  This is a digital illustration in a Japanese a...   \n",
       "2  This is a high-quality illustration in a Japan...   \n",
       "3  This image is a Japanese anime-style illustrat...   \n",
       "4  This is a dramatic and emotional Japanese anim...   \n",
       "\n",
       "                                            short1_1  \\\n",
       "0  A full-body character illustration, featuring ...   \n",
       "1  A digital illustration presenting a portrait o...   \n",
       "2  A high-quality illustration featuring the char...   \n",
       "3  An illustration of Hikari from Arcaea, present...   \n",
       "4  A dramatic and emotional illustration of the c...   \n",
       "\n",
       "                                              short2 fallback  \n",
       "0  A cheerful anime girl with blue twin-drill hai...     NONE  \n",
       "1  In a suggestive pose, Seraphina from Disgaea 5...     NONE  \n",
       "2  A blushing, green-haired Sanae Kochiya in a st...     NONE  \n",
       "3  An ethereal illustration of Hikari from Arcaea...     NONE  \n",
       "4  A distressed anime rabbit-girl with purple hai...     NONE  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unibox as ub\n",
    "\n",
    "\n",
    "df = ub.loads(\"s3://quail-tmp/dive-vis-rubric-gemini-v7/image_list.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Example usage of the slop-forensics shortcuts module.\n",
    "This demonstrates how to use the unified analyze_sentences function.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "# project_root = os.path.dirname(os.path.abspath(__file__))\n",
    "# sys.path.insert(0, project_root)\n",
    "\n",
    "from slop_forensics.shortcuts import analyze_sentences, analyze_multiple_models\n",
    "\n",
    "def main():    \n",
    "    # Example 2: Analyze multiple models/sources\n",
    "    print(\"=== Example 2: Multi-Model Analysis ===\")\n",
    "    \n",
    "    # Sample data from different \"models\" or sources\n",
    "    model_data = {\n",
    "        \"detailed\": df[\"detailed\"].tolist(),\n",
    "        \"short1\": df[\"short1\"].tolist(),\n",
    "        \"short1_1\": df[\"short1_1\"].tolist(),\n",
    "        \"short2\": df[\"short2\"].tolist(),\n",
    "    }\n",
    "    \n",
    "    # Analyze multiple models\n",
    "    multi_results = analyze_multiple_models(\n",
    "        model_sentences=model_data,\n",
    "        output_dir=\"./analysis_results/example_2\",\n",
    "        generate_phylogeny=True  # Generate phylogeny for multiple models\n",
    "    )\n",
    "    \n",
    "    print(f\"Multi-model analysis complete!\")\n",
    "    print(f\"Models analyzed: {multi_results['models_analyzed']}\")\n",
    "    print(f\"Total sentences: {multi_results['total_sentences']}\")\n",
    "    print(f\"Results saved to: ./analysis_results/example_2\")\n",
    "    print()\n",
    "    \n",
    "    print(\"=== Analysis Complete ===\")\n",
    "    print(\"Check the output directories for detailed results:\")\n",
    "    print(\"  - analysis_summary.json: Human-readable summary\")\n",
    "    print(\"  - slop_lists/: Generated slop word lists\")\n",
    "    print(\"  - phylogeny/: Phylogenetic tree visualizations (if generated)\")\n",
    "    print(\"  - analysis/: Detailed analysis metrics\")\n",
    "\n",
    "\n",
    "def quick_analyze(sentences, output_dir=\"./quick_analysis\"):\n",
    "    \"\"\"Quick analysis function for simple use cases.\"\"\"\n",
    "    results = analyze_sentences(\n",
    "        sentences=sentences,\n",
    "        output_dir=output_dir,\n",
    "        model_name=\"quick_analysis\",\n",
    "        generate_phylogeny=False\n",
    "    )\n",
    "    \n",
    "    # Print quick summary\n",
    "    print(\"Quick Analysis Results:\")\n",
    "    print(f\"  Sentences analyzed: {len(sentences)}\")\n",
    "    print(f\"  Average length: {results['statistics'].get('avg_length', 0):.1f} characters\")\n",
    "    print(f\"  Slop score: {results['statistics'].get('slop_score', 0):.3f}\")\n",
    "    print(f\"  Repetitive words: {results['statistics'].get('num_repetitive_words', 0)}\")\n",
    "    \n",
    "    # Show top repetitive words if any\n",
    "    analysis_file = results[\"output_paths\"].get(\"analysis\")\n",
    "    if analysis_file and os.path.exists(analysis_file):\n",
    "        import json\n",
    "        with open(analysis_file, 'r') as f:\n",
    "            analysis_data = json.load(f)\n",
    "        \n",
    "        top_words = analysis_data.get(\"top_repetitive_words\", [])[:5]\n",
    "        if top_words:\n",
    "            print(\"  Top repetitive words:\")\n",
    "            for word_data in top_words:\n",
    "                word = word_data.get(\"word\", \"\")\n",
    "                score = word_data.get(\"score\", 0)\n",
    "                print(f\"    - '{word}' (score: {score:.2f})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Raw data provided\n",
    "data = {\n",
    "    \"short2\": {\n",
    "        \"avg_length\": 119.06,\n",
    "        \"vocab_complexity\": 64.2949,\n",
    "        \"slop_score\": 9.5271,\n",
    "        \"total_unique_words_after_filters\": 45,\n",
    "        \"avg_corpus_rarity\": 1.7422,\n",
    "        \"avg_wordfreq_rarity\": 4.2106,\n",
    "        \"rarity_correlation\": 0.213,\n",
    "        \"repetition_score\": 100.0\n",
    "    },\n",
    "    \"short1_1\": {\n",
    "        \"avg_length\": 1024.01,\n",
    "        \"vocab_complexity\": 60.5155,\n",
    "        \"slop_score\": 13.4961,\n",
    "        \"total_unique_words_after_filters\": 494,\n",
    "        \"avg_corpus_rarity\": 2.8872,\n",
    "        \"avg_wordfreq_rarity\": 4.5503,\n",
    "        \"rarity_correlation\": 0.2935,\n",
    "        \"repetition_score\": 16.0574\n",
    "    },\n",
    "    \"short1\": {\n",
    "        \"avg_length\": 1101.9,\n",
    "        \"vocab_complexity\": 64.4827,\n",
    "        \"slop_score\": 13.1828,\n",
    "        \"total_unique_words_after_filters\": 524,\n",
    "        \"avg_corpus_rarity\": 2.9259,\n",
    "        \"avg_wordfreq_rarity\": 4.5546,\n",
    "        \"rarity_correlation\": 0.2708,\n",
    "        \"repetition_score\": 15.4452\n",
    "    },\n",
    "    \"detailed\": {\n",
    "        \"avg_length\": 4332.79,\n",
    "        \"vocab_complexity\": 56.1503,\n",
    "        \"slop_score\": 11.9596,\n",
    "        \"total_unique_words_after_filters\": 1606,\n",
    "        \"avg_corpus_rarity\": 3.5071,\n",
    "        \"avg_wordfreq_rarity\": 4.8591,\n",
    "        \"rarity_correlation\": 0.3325,\n",
    "        \"repetition_score\": 4.9497\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data).T.reset_index().rename(columns={\"index\": \"model_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7489ac0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox': array([  4, 330, 319, 669]),\n",
       " 'bbox_score': 0.8553559184074402,\n",
       " 'height': 1024.0,\n",
       " 'width': 768.0,\n",
       " 'crop_id': '3y1ge2srvq9',\n",
       " 'source_id': '4yokxqvwmrg',\n",
       " 'label': 'GOOD',\n",
       " 'score': array([9.99912024e-01, 8.79269865e-05]),\n",
       " 'dataset_from': 'incantor/hands-scorer-pixai-v12',\n",
       " 'image_path_csway': '/data/zhizhuo/datasets/pixai_50k_apr25/adea1901-a2f8-4be5-b93d-404b10df49ed.webp'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_dict = combined_df.iloc[0].to_dict()\n",
    "sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa836c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox': array([  4, 330, 319, 669]),\n",
       " 'bbox_score': 0.8553559184074402,\n",
       " 'height': 1024.0,\n",
       " 'width': 768.0,\n",
       " 'crop_id': '3y1ge2srvq9',\n",
       " 'source_id': '4yokxqvwmrg',\n",
       " 'label': 'GOOD',\n",
       " 'score': array([9.99912024e-01, 8.79269865e-05]),\n",
       " 'dataset_from': 'incantor/hands-scorer-pixai-v12',\n",
       " 'image_path_csway': '/data/zhizhuo/datasets/pixai_50k_apr25/adea1901-a2f8-4be5-b93d-404b10df49ed.webp'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_dict = combined_df.iloc[0].to_dict()\n",
    "sample_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
